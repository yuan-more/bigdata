
课前回顾:
	
1) 大数据基本导论:
	什么是大数据:  无法通过一些常规手段, 对数据进行分析处理
	大数据的特点:  大量, 高速, 多样化, 低价值密度
	大数据的作用:  各行各业都需要大数据来进行数据的存储和数据的分析
	大数据的发展前景: 
2) 大数据课程的预备知识:
	服务器: 本质上就是高配置的电脑
	机架:  存放服务器的架子, 用来统一管理
	IDC数据中心: 提供数据的托管服务, 提高用户的访问的效率
	磁盘的存储raid方案: 如何组件更大的磁盘
		raid 0  raid  1
3) 大数据的环境统一: 
4) zookeeper基本内容: 是一个集群管理的工具 小文件的存储系统
	架构方案:  leader  , follower  observer
	zookeeper的特点:  
	zookeeper的数据模型:  
		节点类型:  四种节点类型
	zookeeper的集群安装
	zookeeper的watch机制:  会操作
	zookeeper的shell命令的操作
	zookeeper的JavaAPI的操作
	
	
	
	
今日内容:
1) hadoop的发展历程
2) hadoop历史版本 
3) hadoop的三大发行公司 (CDH)
4) hadoop的模块介绍  
5) hadoop的架构:  (2.x版本的架构模型, 一定要理解, 并记忆)
6) hadoop的部署方案 (了解)
7) CDH版本hadoop重新编译 (知道就行)
8) hadoop的集群安装 (操作, 必须搞定)
9) hadoop的初体验 (操作)
10) hadoop中jobhistory(知道是干什么用的, 会使用) 
11) hadoop的垃圾桶机制 (知道是干什么用的, 会使用)



1) hadoop的发展历程
	网络最早是在美国出现的
	Google: 搜索引擎
		爬虫技术:  爬数据, 网页爬虫
			假设一个网页 200kb
		如何搜索问题:  Google自己专门有了实现搜索的产品

	Google的三大核心技术: Google的三驾马车
		GFS(分布式的文件存储系统) MapReduce(分布式计算框架),BIgTable(大表)

	2003,2004年时候, 将自己的三驾马车写成论文的方式, 进行发表
		

	Doug Cutting在2003年的看到了Google发表论文
		最早做爬虫的, 写通用爬虫(Nutch),
		第一个问题: 如何快速的检索数据:	随手写了技术:  lucene(全文的搜索技术)
		第二个问题: 如何存储数据. 直到2003年看到了Google的论文
		
	2005年的时候, 依据GoogleGFS 和MapReduce 写出了框架:  hadoop(GFS + MapReduce)
	加入了雅虎, 2008年时候将hadoop贡献给apache, 称为了apache顶级项目
		2008年的时候, cloudera公司诞生了
	
	Doug Cutting整个大数据鼻祖
	
	
	
2) hadoop历史版本: 四个版本了
		0.x的版本: hadoop最初始的版本   0.20版本
		1.x的版本: 基于0.x实现的版本, 主要是对0.x版本的bug进行解决  1.20版本
		2.x的版本: 整个架构发生最大的改变  2.2.0版本  2.6.0版本
		3.x的版本: 基于2.x版本实现的
		
3) hadoop三大发行公司:
	apache:  最大的开源社区, 
			好处: 版本的更新迭代非常快
			缺点: 只管更新, 不管是否能够和其他的软件兼容
		在生产环境下, 不推荐使用的
	Hortonworks: 雅虎组建, 开源免费
		提供了一个web管理界面, 通过管理界面, 非常方便安装各种大数据的软件, 
			而且兼容问题也进行解决  HDP软件
	clouderaManager: 2008年, 是一家商业公司
		提供了一个web管理界面, 通过管理界面, 非常方便安装各种大数据的软件, 
			而且兼容问题也进行解决 CDH5
		
		基础软件是免费使用的, 如果要使用一些的高级服务, 需要收费的
		在2008年 10年. cloudera公司将Hortonworks 收购了 
		CDH版本, 推荐使用
		cdh下载地址:  http://archive.cloudera.com/cdh5/cdh/5/
		
		使用版本;  CDH5.14.0, 如果以后在面试中, 问到使用hadoop的那个版本, 只需要说明CDH5.14.0
			在CDH中, 如果版本是一样的, 那么就可以直接使用, 不需要考虑兼容问题
		
		
4)  apache的hadoop和 CDH的hadoop目录结构对比:
		apache的目录结构:
			bin : 对hadoop集群操作的命令
			etc\hadoop:  hadoop的配置文件存储目录
			lib\native: 存储hadoop的访问c语言接口. 主要是用来执行数据的压缩(snappy)
			sbin :存储了启动和关闭hadoop集群的一些脚本
			share:  存储了hadoop的测试的jar包, hadoop执行的jar包, 帮助文档
		
		CDH版本的目录结构:
			bin : 对hadoop集群操作的命令
			etc\hadoop:  hadoop的配置文件存储目录
			sbin :存储了启动和关闭hadoop集群的一些脚本
			share:  存储了hadoop的测试的jar包, hadoop执行的jar包, 帮助文档
			cloudera:  cloudera公司对hadoop的版本的优化升级的补丁, 已经和其他兼容的补丁
			lib\native: 存储hadoop的访问c语言接口. 主要是用来执行数据的压缩(snappy)
				在CDH版本中, native目录下, 没有任何的访问C语言的接口,
				在cloudera公司在对源码进行编译的时候, 并没有行C语言的接口放置到目录中, 推荐使用
					使用CDH公司的压缩方案, 或者使用java的压缩方案
				
				如果想要使用C语言的访问接口, 需要进行重新的编码, 让其支持C语言的压缩方案
				
		目的有二个: 第一个 Cdh对hadoop	做了版本兼容, 第二个 如果CDH的hadoop需要进行重新的编码
		
				
5) hadoop的模块组成:  1.x  和 2.x
		1.x:  对hadoop主要分为两部分:
			HDFS(GFS): 分布式的文件存储系统
			MapReduce:  分布式的计算框架	  离线计算
		
		2.x: 将hadoop分为了两部分	
			HDFS: 分布式的文件存储系统
			YARN:  统一的资源调度平台
				资源:  CPU  内存 磁盘
			MapReduce: 内嵌到yarn平台上面, 提供计算的业务
				
		一个程序的运行, 必须依赖于资源, 如果没有资源, 压根就运行不了程序
6) hadoop的架构: 

	1.x: 架构模型:
		hdfs: 分布式的文件存储系统
			namenode :  hdfs集群中主节点  只能存在一个, 不能有多个
				对hdfs集群的进行管理, 存储文件的元数据信息
			
			
			secondarynamenode: 用来辅助namenode管理元数据信息
			datanode: : hdfs集群中从节点  可以存在多个的
				存储数据的
		
		MapReduce:  分布式的计算框架
			jobTracker: 主节点    只能存在一个, 不能有多个
				接收任务的请求, 对任务继续分配
			TaskTracker:   从节点,, 可以有多个
				接收jobTracker分配的任务, 执行任务
	
		1.x有单节点的故障: 一旦主节点宕机, 那么整个集群也就宕机了
	
	
元数据:  描述数据的数据
		

例子:  想去图书馆, 租一本书 <<葵花宝典>>
	先找到这本书: 请问如何找:
		
		1) 这本书是那个分类的书: 武林秘籍
		2) 知道这个分类的书都在那层上面, 知道在那个书架上面
		3) 知道在这个书架 的那一层, 编号是多少
		
		<<葵花宝典>>:  描述这个本书的数据有哪些:
			属于那个分类, 在那一层, 在那个书架上, 在书架的那一层, 编号是多少

		图书管理系统:存储的数据其实就是存储了各个数对应的位置关系
		而这些信息都是用来描述这个本书是的数据, 而且和这本书没有直接的关联,
			描述这个本书的数据其实就是元数据的信息

例子: 判断你的同桌是你昨天的那个同座吗?
	1) 是男是女
	2) 姓名
	3) 面孔, 衣服, 头发....


例子: 文件系统  windows
	在文件系统下, 会有很多的很多的文件, 而文件就是存储数据
	
	除了文件以外:  还有文件的描述信息
		文件的存储目录在哪里
		文件的大小
		文件是在什么时候创建的, 什么时候修改过
		文件属于的权限有那些
		
如果元数据信息, 没有了呢? 能到找这个文件吗? 答案是肯定找不到的
	在进行删除一个文件的时候, 其实本质上就是删除了元数据信息, 所有删除操作一般都是非常快的
	
	
2.x的架构模型 :   一定要能够理解, 并且将其记忆
	hdfs:
		
		namenode:  是hdfs的主节点,  可以有多个, 但是最多只能有二个
			管理hdfs的集群, 保存元数据信息 
		
		datanode :  是hdfs的从节点 , 可以有多个, 理论上没有大小的限制
			存储数据
		
		snn:  辅助管理namenode的元数据信息
			如果使用的高可用方案 , 就没有snn, 但是会有一个 journalNode, 通过journal实现
				两个namenode元数据的拷贝操作, 保证两个namenode中元数据是相同的, 避免出现
					文件的脑裂问题
				
	
	yarn平台:
		resourceManager: yarn平台 的主节点, 可以有多个, 但是最多只能有二个
			接收任务的请求, 进行任务的资源的分配, 启动appMaster
		
		
		appMaster:   是一个进程, 运行在nodemanager上面
			主要作用:  进行资源的申请, 任务进行分配
			
		
		nodeManger:  yarn平台的从节点, 可以有多个, 理论上也没有限制
			接收 appMaster的分配任务
			
	
	
	从1.x 改变 2.x 好处:
		1.避免了单节点故障
		2. 对任务和资源分配划分更加的明确了, 
			在1.x中 jobTracker 资源和任务的分配, jobTracker任务是比较重的,一旦任务多了, 就会出现宕机风险
			在2.x中 resourceManager进行资源的分配, 专门启动一个进程appMaster来任务的分配
		3. 提供了统一的资源调度平台, 可以将其他的计算框架融入到yarn平台中
	
7) hadoop的三种运行方式 : 
	第一种运行模式:  standAlone  (单机模式)
		不需要安装hadoop的集群, 直接使用本地运行的方式,来执行计算的任务
			在开发环境下使用这种方式, 方便测试
			
			
	第二种运行模式:  伪分布式的运行模式
		将hadoop集群中所有的节点都安装在一台服务器中, 和完全分布式的通信方式都是一样的, 
			唯一的区别的就在一个, 一个是只在一台服务器, 一个是在多台服务器中
				主要在学习(测试)环境下使用, 存在单节点故障
				
	第三种运行模式: 分布式的运行模式
		将各个节点都分配到不同的服务器中, 进行分开部署, 实现分布式
			适用于 生产环境下
	
	目前搭建的分布式的运行模式:  伪分布式方式(用三台来搭建)
	
	
8) 如果要使用cdh的hadoop  需要重新编译 (不需要大家去操作)

	

9) hadoop集群搭建:
		注意:  mapred-site.xml 需要先进行改名后, 才能修改内容, 否则不生效
	
		注意: 如果是第一次启动hadoop, 必须对hadoop进行格式化操作:之后不需要在执行
			hadoop namenode Cformat
	 如何启动hadoop: 主要二种方式启动
		一种: 通过命令, 一个节点一个节点启动
			hadoop-daemon.sh start namenode : node01
			hadoop-daemon.sh start datanode : node01,node02,node03
			hadoop-daemon.sh start secondarynamenode : node01
			yarn-daemon.sh start resourcemanager : node01
			yarn-daemon.sh start nodemanager  : node01,node02,node03
			mr-jobhistory-daemon.sh start historyserver : node01
			
			将上述命令中 start 更改为 stop即可

		一种: 通过集群命令: 一次性启动多个节点
			start-dfs.sh   启动hdfs集群
			start-yarn.sh  启动yarn平台
			mr-jobhistory-daemon.sh start historyserver  启动historyserver
			
			停止脚本:
				stop-dfs.sh   停止hdfs集群
				stop-yarn.sh  停止yarn平台
				mr-jobhistory-daemon.sh stop historyserver  停止historyserver
				
				
	集群访问的方式: 
		hdfs集群访问地址
			http://192.168.52.100:50070/dfshealth.html#tab-overview  
		yarn集群访问地址
			http://192.168.52.100:8088/cluster
		jobhistory访问地址：
			http://192.168.52.100:19888/jobhistory		
10) hadoop集群的初体验:
	10/1)  如何来操作hdfs文件系统:
			hadoop fs  操作命令
			hdfs  dfs  操作命令   ---- 推荐使用第二种, 新版本推荐
		命令1: 如何在hdfs上面创建文件夹:
			hdfs  dfs -mkdir -p path
			
			注意: 如果在创建文件夹的时候, 没有书写 /  表示在当前用户在hdfs的家目录创建
					/user/{用户名}/对应文件目录
		命令2:  如何上传一个文件到hdfs的文件系统中
			hdfs dfs  -put  srcPath   hdfsFilePath
			
		命令3: 查看hdfs中目录列表:
			hdfs hdfs  -ls hdfsPath
		命令4: 删除一个文件或者文件夹
			hdfs dfs -rm -r  hdfsPath
			如果开启了垃圾桶机制, 会将文件移动垃圾桶的目录下
		命令5 : 指定移动hdfs的命令
			hdfs dfs -mv hdfsSrcPath  distHdfsPath
			
	10/2)  MapReduce是否可以执行 :
		执行MapReduce的jar包, 两种方式:
			hadoop jar  jar路径  mapNum  reduceNum
			
			yarn  jar jar路径  mainClass  args   --推荐使用


11) jobHistory:  是用于查看MapReduce在执行完以后的日志文件的
		会将MapReduce在各个节点执行完成后的日志给汇总在一起, 然后提供一个可视化的界面
			供我们查询日志
			
			
		MapReduce在执行的时候, 需要将MapReduce打包成一个jar包, 然后扔给yarn平台来执行, 无法查看到着呢整个执行的过程,
			一旦MapReduce执行失败, 也并不知道错在哪里, 报了什么错误
		所以hadoop提供了 jobHistory, 用来收集MapReduce执行的日志信息, 将信息汇总让用户查询
		
		如果以后在执行MapReduce中, 如果发现程序没有执行成功 怎么办:
			需要查询jobHistory中对应任务的日志信息, 找有没有报一些错误
	

12) hdfs的垃圾桶机制:  类似于 window中回收站
		在window中有没有垃圾桶:  指的那个回收站
		
	任何一个文件系统, 都会垃圾桶机制 :
	
	垃圾桶主要目的: 防止用户不小心删错文件, 提供一个恢复 的过程
	
	
	在hdfs中, 同样也有垃圾桶的机制, 一般建议将其开启, 万万不可将其关闭
	
		<property>
			<name>fs.trash.interval</name>
			<value>10080</value>
		</property>
		上面的配置, 描述在什么时候删除垃圾桶中的数据, 默认是  7天 如果在垃圾桶中存储文件大于7天, 自动删除
	
	在生产环境下, 删除一个文件, 先将其放置到垃圾桶中就可以了, 等待超时自动删除即可
	
	
	如何使用垃圾桶: 
		hdfs dfs -rm -r  hdfspath  : 只要开启垃圾桶, 自动将数据移动垃圾桶中
		
		hdfs dfs -rm -r -skipTrash hdfsPath: 跳过垃圾桶, 直接删除(慎用)
	
		如何还原被放置垃圾桶的文件或者文件夹:
			hdfs dfs -mv 垃圾桶目录 移动的目的目录
	
	垃圾桶基本原理: 
		在执行删除一个文件或者文件夹的时候, 本质上就是将这个文件或者文件夹移动到垃圾桶的目录下,
			如果要进行还原操作, 实际上就是从垃圾桶中将这个文件在移动到对应目录下
			
	

总结: 
	1) hadoop的发展历程 : 先有需求, 才会软件产生
		Doug Cutting (大数据的鼻祖)
	
	2) hadoop的历史版本:  四大版本
		0.x     0.20
		1.x     1.2.0
		2.x		2.2.0  2.6.0(2015年)  CDH中5.14.0 是在2018才有的
		3.x    
	
	3) hadoop三大发行公司:
		apache  : 免费开源的, 只管升级, 不管是否可以和其他的软件进行兼容
		hortonworks : 免费开源的,   对软件的兼容进行了优化, 提供了可视化的管理界面
		cloudera  : 基础服务是免费的  对软件的兼容进行了优化, 提供了可视化的管理界面
				CDH5 : 5.14.0
	4) hadoop的模块组成:  1.x  和 2.x
		1.x: 两个部分  hdfs  MapReduce
		2.x: 两个部分  hdfs  yarn
	5) hadoop的架构模型: 1.x  和 2.x
	6) hadoop的三种运行方式 :  
	7) CDH版本的hadoop重新编译 : 
	8) hadoop集群的安装(参考的课件): 一定将其搭建起来
	9) hadoop的初体验:  
	10) jobHistory的基本使用 : 查看日志
	11) 垃圾桶机制:  理解windows 回收站
	
	
			
			